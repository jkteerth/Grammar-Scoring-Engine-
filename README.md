ğŸ™ï¸ Grammar Scoring Engine from Voice 

(Python | AI | Offline ASR | ML Grammar Scoring)

ğŸ“Œ Project Overview

This project is an AI-based Grammar Scoring Engine that evaluates spoken English from audio  inputs.
It converts speech to text, corrects grammatical errors using pretrained transformer models, and produces a grammar score out of 100 with visual feedback.

The system supports:

ğŸ§ Audio upload (WAV, MP3, M4A, FLAC, OGG)

ğŸ¤ Live voice recording (Start / Stop)

ğŸ“Š Grammar score visualization

ğŸŒŠ Audio waveform visualization
 
ğŸ“Š  provide the the corrected sentence and input sentence 

ğŸ–¥ï¸ Modern CustomTkinter UI

ğŸŒ Flask web version (optional)

This project was developed as part of an SHL assessment and follows industry-grade design practices.

ğŸš€ Key Features

â— Offline Speech Recognition (Vosk â€“ no internet required)

â— Grammar Correction using Transformers (T5-base)

â— ML-based Grammar Scoring (0â€“100)

â— Audio Support

â— Waveform Visualization

â— Animated Score Visualization

â— Threaded Processing (No UI Freeze)

â— Cross-Platform (Windows tested)

ğŸ§  Architecture Pipeline
Audio / Video Input
        â†“
FFmpeg (Normalize & Extract Audio)
        â†“
Vosk ASR (Speech â†’ Text)
        â†“
T5 Grammar Correction Model
        â†“
Grammar Scoring Logic
        â†“
Visualization (Waveform + Score)

ğŸ“ Project Structure
SHL/
â”‚
â”œâ”€â”€ app.py                     # Main UI launcher
â”œâ”€â”€ README.md                  # Project documentation
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ speech_to_text.py      # Vosk ASR
â”‚   â”œâ”€â”€ grammar_corrector_ml.py
â”‚   â””â”€â”€ grammar_scorer_ml.py
â”‚
â”œâ”€â”€ audio/
â”‚   â”œâ”€â”€ recorder.py
â”‚   â””â”€â”€ audio_utils.py
â”‚
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ main_ui.py             # CustomTkinter UI
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ text_compare.py
â”‚
â””â”€â”€ vosk-model-en-us-0.22-lgraph/

âš™ï¸ Technologies Used
Component	Technology
Language	Python 3.11
UI	CustomTkinter
ASR	Vosk (Offline)
Grammar Correction	T5-base Transformer
Audio Processing	FFmpeg, PyDub
Visualization	Matplotlib
Threading	Python threading
Optional Web	Flask
ğŸ§ª Supported Input Formats
ğŸ§ Audio

WAV

MP3

M4A

FLAC

OGG

ğŸ› ï¸ Installation & Setup (Windows)
1ï¸âƒ£ Clone or Download Project
cd C:\Projects

2ï¸âƒ£ Create Virtual Environment
python -m venv venv
venv\Scripts\activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

ğŸ”Š FFmpeg Setup (Required)
Download FFmpeg

https://www.gyan.dev/ffmpeg/builds/

Extract to:

C:\ffmpeg-8.0.1-essentials_build\


Add to System PATH:

C:\ffmpeg-8.0.1-essentials_build\bin


Verify:

ffmpeg -version

ğŸ§  Download Vosk Model (Offline ASR)

Download:

vosk-model-en-us-0.22-lgraph


Place it in the project root:

SHL/vosk-model-en-us-0.22-lgraph/

â–¶ï¸ Run the Application
python app.py

ğŸ–¥ï¸ How to Use

Upload Audio OR Upload Video

OR click Start Recording â†’ Stop Recording

Click Score & Process

View:

â— Original text

â— Corrected sentence

â— Grammar score

â— Waveform

Animated score chart

ğŸ“Š Grammar Scoring Logic

 â€£ Grammar is corrected using a pretrained T5 transformer

 â€£ Score is calculated based on:

â€£ Degree of correction

â€£ Structural differences

â€£ Score range: 0â€“100

Designed to produce realistic human-like scores

â€œThe system uses offline speech recognition, transformer-based grammar correction, and ML-driven scoring to evaluate spoken English from audio and video inputs. It is fully offline, scalable, and reproducible.â€

ğŸ”® Future Enhancements

â— Browser-based microphone & camera

â— CEFR level prediction (A1â€“C2)

â— PDF report export

â— Web deployment (Flask / HuggingFace Spaces)

â— Confidence scoring per sentence

ğŸ‘¨â€ğŸ’» Author
Focused on ML, NLP, and Speech Processing 
